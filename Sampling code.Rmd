---
title: "Untitled"
output: html_document
date: "2023-03-04"
---
```{r}
library(tidyverse)

#Creating dataset to match that of the client using the infomation from the crosstabs breakdown of variables

region <- c(rep("NE",4576),rep("NW",14187),rep("Y&H",10864),rep("EM",11153),rep("WM",12325),rep("EE",17573),rep("L",27574),rep("SE",26831),rep("SW",18412),rep("W",7138),rep("S",303),rep("U",2009))
#For size 1=0-10k, 2 10-100k, 3 100k-1m, 4 1m-10m, 5 10m+
size <- c(rep(1,1759),rep(2,1718),rep(3,898),rep(4,179),rep(5,22),
          rep(1,5471),rep(2,5437),rep(3,2662),rep(4,521),rep(5,96),
          rep(1,4324),rep(2,4190),rep(3,1941),rep(4,356),rep(5,53),
          rep(1,5079),rep(2,4048),rep(3,1682),rep(4,283),rep(5,61),
          rep(1,5080),rep(2,4664),rep(3,2079),rep(4,418),rep(5,84),
          rep(1,7601),rep(2,6635),rep(3,2745),rep(4,463),rep(5,129),
          rep(1,8462),rep(2,9408),rep(3,7065),rep(4,2164),rep(5,475),
          rep(1,9822),rep(2,11111),rep(3,4709),rep(4,955),rep(5,234),
          rep(1,7792),rep(2,7173),rep(3,2833),rep(4,511),rep(5,103),
          rep(1,3164),rep(2,2702),rep(3,1037),rep(4,201),rep(5,34),
          rep(1,119),rep(2,117),rep(3,51),rep(4,15),rep(5,1),
          rep(1,614),rep(2,763),rep(3,473),rep(4,128),rep(5,31))

#Putting infomation into dataset and setting variables to be factors
charity.data <- data.frame("id"=sample(1:152945, 152945,replace=F),
                           "region"=region,
                           "size"=size)%>%
  mutate(region=factor(region,levels=c("NE","NW","Y&H","EM","WM","EE","L","SE","SW","W","S","U"),
                       labels=c("North East","North West","Yorkshire & the Hum","East Midlands","West Midlands","East of England","London","South East","South West","Wales","Scotland","Unkown")),
         size=factor(size,levels = c(1:5),labels = c("0-10k","10k-100k","100k-1m","1m-10m","10m+")))
```

```{r}
#looking at frequencies and proportions
table(charity.data$size)
table(charity.data$region)

prop.table(table(charity.data$size))
prop.table(table(charity.data$region))

table(charity.data$region,charity.data$size)
prop.table(table(charity.data$region,charity.data$size),margin=1) #proportions by row
prop.table(table(charity.data$region,charity.data$size),margin=2) #proportions by column

# # #stratifying only by size
# # for (i in c("0-10k","10k-100k","100k-1m","1m-10m","10m+")){
# #   assign(paste0("charity.size.",i),filter(charity.data,size==i)) 
# # }
# 
# Sample.vectors <- list() #list to store sampled charities in 
# 
# #stratifying by size then region then sampling (with oversampling on smaller [populations])
# for (i in c("0-10k","10k-100k","100k-1m","1m-10m","10m+")){
#   assign(paste0("charity.size.",i),filter(charity.data,size==i)) #creating a separate dataset for each size category
#   for (j in c("North East","North West","Yorkshire & the Hum","East Midlands","West Midlands","East of England","London","South East","South West","Wales","Scotland","Unkown")){
#     assign(paste0("charity.",i,".",j),filter(get(paste0("charity.size.",i)),region==j)) #creating a separate dataset for each region within each size category dataset
#     #Now sampling from within each size region dataset - added rules for what proportion to sample based on sample size to maintain a good sized sample for each group without sampling too much from the groups with larger populations (as have a max sample size of 7000)
#     if(dim(get(paste0("charity.",i,".",j)))[1]<100){
#       assign(paste0("sample.charity.",i,".",j),select(get(paste0("charity.",i,".",j)),id)) #If total number of charities in size region less than 100 take whole population
#     }
#     else if(dim(get(paste0("charity.",i,".",j)))[1]<250){
#       assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*0.8)))
#     }
#     else if(dim(get(paste0("charity.",i,".",j)))[1]<500){
#       assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*0.45)))
#     }
#     else if(dim(get(paste0("charity.",i,".",j)))[1]<1000){
#       assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*0.15)))
#     }
#     else{
#       assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=120)) #sample 100
#     }
#     Sample.vectors <- append(Sample.vectors,get(paste0("sample.charity.",i,".",j)),after=length(Sample.vectors))
#   }
# }
# 
# Sample.vectors<-unlist(Sample.vectors) #can play around with the percentages sampled from each size region group (currently samples over 30 from each group unless less than 30 in group in which case it takes all)
# 
# #Matching with original data
# sampled.charities.df <- merge(data.frame("id"=Sample.vectors),charity.data,by="id")
```


```{r}
#Making sampling into function so client can use much easier

Stratified.sample.func <- function(charity.data,prop.lt.100,prop.lt.250,prop.lt.500,prop.lt.1000,num.gt.1000){
Sample.vectors <- list() #list to store sampled charities in 

#stratifying by size then region then sampling (with oversampling on smaller [populations])
for (i in c("0-10k","10k-100k","100k-1m","1m-10m","10m+")){
  assign(paste0("charity.size.",i),filter(charity.data,size==i)) #creating a separate dataset for each size category
  for (j in c("North East","North West","Yorkshire & the Hum","East Midlands","West Midlands","East of England","London","South East","South West","Wales","Scotland","Unkown")){
    assign(paste0("charity.",i,".",j),filter(get(paste0("charity.size.",i)),region==j)) #creating a separate dataset for each region within each size category dataset
    #Now sampling from within each size region dataset - added rules for what proportion to sample based on sample size to maintain a good sized sample for each group without sampling too much from the groups with larger populations (as have a max sample size of 7000)
        if(dim(get(paste0("charity.",i,".",j)))[1]==1){
      assign(paste0("sample.charity.",i,".",j),select(get(paste0("charity.",i,".",j)),id)[[1]]) #If only 1 value need to select that value as sample function behaves differently with only 1 input
    }
    else if(dim(get(paste0("charity.",i,".",j)))[1]<100){
      assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*prop.lt.100))) 
    }
    else if(dim(get(paste0("charity.",i,".",j)))[1]<250){
      assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*prop.lt.250)))
    }
    else if(dim(get(paste0("charity.",i,".",j)))[1]<500){
      assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*prop.lt.500)))
    }
    else if(dim(get(paste0("charity.",i,".",j)))[1]<1000){
      assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=ceiling(dim(get(paste0("charity.",i,".",j)))[1]*prop.lt.1000)))
    }
    else{
      assign(paste0("sample.charity.",i,".",j),sample(select(get(paste0("charity.",i,".",j)),id)[[1]],size=num.gt.1000)) #sample 100
    }
    Sample.vectors <- append(Sample.vectors,get(paste0("sample.charity.",i,".",j)),after=length(Sample.vectors))
  }
}

Sample.vectors<-unlist(Sample.vectors) #can play around with the percentages sampled from each size region group (currently samples over 30 from each group unless less than 30 in group in which case it takes all)

#Matching with original data
sampled.charities.df <- merge(data.frame("id"=Sample.vectors),charity.data,by="id")
return(sampled.charities.df)
}
#sampling using stratifing function
sample.dataset<-Stratified.sample.func(charity.data,1,0.8,0.45,0.15,120)
```


```{r}
#investigating sampled dataset
table(sample.dataset$region,sample.dataset$size)

#Will have to weight those over sampled appropriately (use prop in population/prop in sample then sum to find total aggregate) THINK ABOUT THIS A BIT MORE
```






